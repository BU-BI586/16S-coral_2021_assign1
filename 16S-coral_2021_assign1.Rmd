---
title: "Grey Patch Disease in Coral and 16S Analysis of Bacteria"
author: "Susritha Kopparapu, Isabel Novick, Corinne Vietorisz"
date: "2/28/2021"
output: html_document
---
## Introduction

insert introduction 

## Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### R Version
R version 4.0.2 was used for this analysis. 

#### Packages
The following packages were used to clean, analyze, and visualize data. Packages were installed with [Bioconductor](https://bioconductor.org/biocLite.R) version 3.12 using the vegan package. 
```{r, message=FALSE}
library(dada2);         #Version 1.18.0
library(ShortRead);     #Version 1.48.0
library(ggplot2);       #Version 3.3.3
library(phyloseq);      #Version 1.34.0
```

```{r, echo=FALSE, eval=FALSE}
packageVersion("dada2"); citation("dada2")
packageVersion("ShortRead")
packageVersion("ggplot2")
packageVersion("phyloseq")
```

#### Data Retrieval
[Sweet et. al 2019](https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-019-0759-6) collected samples from healthy and diseased *Porites lobata*, as well as the water column of the Luminao reef flat in Guam (in 2016). Their data that was reanalyzed here was retrieved from [NCBI](https://www.ncbi.nlm.nih.gov/sra?LinkName=bioproject_sra_all&from_uid=448821).

Samples diseased 13, healthy 11, healthy 4, diseased 14, water column 2 were selected. All files in the directory were put in the variable fns. 
```{r,eval=FALSE}
path <- "/projectnb/bi594/skoppara/Assignment1"
fns <- list.files(path)
fns
```

## Trimming and Filtering Data
Filter through all the files and find only the fastq files. Sort them so that the reads are in the same order. 
```{r, eval=FALSE}
fastqs <- fns[grepl(".fastq$", fns)]
fastqs <- sort(fastqs) 
fastqs
```

Split and store each of the files names as sample names without the .fastq file extension. Store these in another variable.
```{r, eval=FALSE}
sample.names <- sapply(strsplit(fastqs, ".fastq")
fnFs <- file.path(path, fastqs)
fnFs
```


#### Visualize Raw Data

Plot the quality of the reads to visually analyze. 
```{r, eval=FALSE}
plotQualityProfile(fnFs[c(1,2,3,4,5,6,7,8,9)])
plotQualityProfile(fnFs[c(10,11,12,13,14,15,16,17,18)])
plotQualityProfile(fnFs[c(19,20,21,22,23,24,25,26,27)])
plotQualityProfile(fnFs[c(28,29,30,31,32,33,34,35)])
plotQualityProfile(fnFs[c(36,37,38,39,40,41)])
```
The quality stays above 20 for the whole length of the sequences, however the quality does drop a little around 150 which is why that was chosen as the truncation length. 

A directory is made for the filtered files and filenames using the following code. 
```{r, eval=FALSE}
filt_path <- file.path(path, "trimmed")
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
```

The truncation length was defined to 150. No Ns are allowed and expected errors allowed was 1. N nucleotides to remove from the start was 31 because each 16S primer = F 31 bp. 
```{r, eval=FALSE}
out <- filterAndTrim(fnFs, filtFs, truncLen= 150,
                     maxN=0, 
                     maxEE=1, 
                     truncQ=2, 
                     trimLeft=20, #N nucleotides to remove from the start of each read: ITS2 primer = F 20bp
                     rm.phix=TRUE, 
                     compress=TRUE, 
                     multithread=FALSE) 
```

```{r,eval=FALSE}
head(out)
```


## Error Rates
```{r,eval=FALSE}
setDadaOpt(MAX_CONSIST=30) #increase number of cycles to allow convergence
errF <- learnErrors(filtFs, multithread=TRUE)
#Maximum cycles was set to 30, but Convergence was found after 4 rounds

#sanity check: visualize estimated error rates
#error rates should decline with increasing qual score
#red line is based on definition of quality score alone
#black line is estimated error rate after convergence
#dots are observed error rate for each quality score

plotErrors(errF, nominalQ=TRUE) 
```


## Dereplicate Reads
```{r,eval=FALSE}
#Dereplication combines all identical sequencing reads into “unique sequences” with a corresponding “abundance”: the number of reads with that unique sequence. 
#Dereplication substantially reduces computation time by eliminating redundant comparisons.
#DADA2 retains a summary of the quality information associated with each unique sequence. The consensus quality profile of a unique sequence is the average of the positional qualities from the dereplicated reads. These quality profiles inform the error model of the subsequent denoising step, significantly increasing DADA2’s accuracy.
derepFs <- derepFastq(filtFs, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
```


## Infer Sequence Variants
Band size 16 for 16S
```{r,eval=FALSE}
#Must change some of the DADA options b/c original program optomized for ribosomal data, not ITS - from github, "We currently recommend BAND_SIZE=32 for ITS data." leave as default for 16S/18S
setDadaOpt(BAND_SIZE=16)
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)

#now, look at the dada class objects by sample
#will tell how many 'real' variants in unique input seqs
#By default, the dada function processes each sample independently, but pooled processing is available with pool=TRUE and that may give better results for low sampling depths at the cost of increased computation time. See our discussion about pooling samples for sample inference. 
dadaFs[[1]]
dadaFs[[5]]

#construct sequence table
seqtab <- makeSequenceTable(dadaFs)
head(seqtab)
```


## Remove Chimeras
```{r,eval=FALSE}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
# Identified 1 bimeras out of 117 input sequences.

sum(seqtab.nochim)/sum(seqtab)
#The fraction of chimeras varies based on factors including experimental procedures and sample complexity, 
#Most of your reads should remain after chimera removal (it is not uncommon for a majority of sequence variants to be removed though)
#For our sample, this ratio was 0.9998201, there was only 1 bimera

write.csv(seqtab,file="16s_seqtab.csv")
write.csv(seqtab.nochim,file="16s_nochim.csv")
```


## Track Read Stats
```{r,eval=FALSE}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaFs, getN), rowSums(seqtab), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoised", "merged", "tabled", "nonchim")
rownames(track) <- sample.names
head(track)
tail(track)

write.csv(track,file="ReadFilterStats_AllData_final.csv",row.names=TRUE,quote=FALSE)

```


## Assign Taxonomy
```{r, eval=FALSE}
taxa <- assignTaxonomy(seqtab.nochim, "GTDB_bac-arc_ssu_r86.fa", minBoot=5,multithread=TRUE,tryRC=TRUE,outputBootstraps=FALSE)
#minboot should be higher
#Obtain a csv file for the taxonomy so that it's easier to map the sequences for the heatmap.
write.csv(taxa, file="taxa.csv",row.name=TRUE,quote=FALSE)
unname(head(taxa, 30))
unname(taxa)
```

## Visualize Data

```{r,echo=FALSE}
setwd("/projectnb/bi594/skoppara/Assignment1/")

```

```{r}
seqtab.nochim <- readRDS("final_seqtab_nochim.rds")
taxa <- readRDS("final_taxa_blastCorrected.rds")
#head(taxa)
samdf<-read.csv("variabletable.csv")
head(samdf)
#head(seqtab.nochim)
#head(taxa)
rownames(samdf) <- samdf$sample
```

```{r,eval=TRUE}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa))
ps
```


```{r, echo=FALSE}
ids<-taxa_names(ps)
ids <- paste0("sq",seq(1, length(colnames(seqtab.nochim))))
colnames(seqtab.nochim) <- ids

#Bar-plots
top90 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:90]
ps.top90 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top90 <- prune_taxa(top90, ps.top90)

plot_bar(ps.top90, x="Sample", fill="Class") 
```

```{r, echo=FALSE, fig.width=10, fig.height = 8}
#visusalize via counts rather than abundances:
plot_bar(ps, x = "sample", fill= "Class") #+ facet_wrap("tank")
#
```

```{r, echo=FALSE}
#Obtain a csv file for the phyloseq data. Will give you the abundances for each sample and class. Useful for constructing the heatmap. Also, enables you to use ggplot, and construct more aesthetically pleasing plot.
psz <- psmelt(ps.top90)
write.csv(psz, file="Phyloseqoutputfinal.csv")
p <- ggplot(psz, aes(x=Sample, y=Abundance, fill=Class))
p + geom_bar(stat="identity", colour="black")
```


## Conclusion
insert conclusion here

